<div style="margin: auto; width: 65%">
  <img src="{{ site.url }}/img/faait.jpg"
  style="display:block; margin-left:auto; margin-right:auto; border-radius:50%; width:50%;">

  <p style="text-align:center; margin-top:5%; margin-bottom:0%; font-size: 140%; font-family:sans-serif">
    Muhammad Faaiz Taufiq
  </p>
  <p style="text-align:center; margin:0%;">
    <a href="https://www.twitter.com/FaaizTaufiq">
      {% include icon.html id="twitter" title="twitter" %}
    </a>
    &nbsp;
    <a href="https://github.com/faaizT">
      {% include icon.html id="github" title="github" %}
    </a>
    &nbsp;
    <a href="https://www.linkedin.com/in/muhammadftaufiq/">
      {% include icon.html id="linkedin" title="linkedin" %}
    </a>
    &nbsp;
    <a href="https://scholar.google.com/citations?hl=en&user=oDL6ahoAAAAJ">
      {% include icon.html id="google-scholar" title="scholar" %}
    </a>
  </p>
</div>
<br style="line-height:10%;">

I am a Research Scientist at [ByteDance Seed](https://seed.bytedance.com/), London, where I am working on LLM reasoning and multi-agent collaboration. My broader research interests span the robustness and safety of AI systems, with a focus on uncertainty quantification, causal inference, algorithmic fairness, and interpretability.

Prior to this, I completed my PhD in machine learning at Oxford, under the supervision of [Rob Cornish](https://jrmcornish.github.io/), [Arnaud Doucet](https://www.stats.ox.ac.uk/~doucet/) and [Yee Whye Teh](http://www.stats.ox.ac.uk/~teh/), and funded by Google DeepMind. You can find more details in my [PhD thesis](https://arxiv.org/abs/2502.06011).

<!-- My research interests include uncertainty quantification, decision-making, causal inference, fairness and explainability. I am also interested in applying ideas from these disciplines for alignment within Large Language Models (LLMs). -->

<!-- I recently completed a research internship in the Responsible AI team at [ByteDance](https://www.bytedance.com/), London. Here, I was exploring the reliability and trustworthiness of LLMs. -->

I am also a part of the organising committee for [ELLIS RobustML workshops](https://sites.google.com/view/robustml2024). 
In 2024, we organised two robustness-related workshops with the aim of bringing together theoretical robustness research with real-world applications. For updates regarding upcoming workshops, join our [mailing group](https://groups.google.com/g/ellis-robustml-community).
<!-- Prior to this, I also interned at [Amazon](https://aws.amazon.com/) in Tubingen, Germany in 2022, where I worked on [robust explanability methods](https://arxiv.org/abs/2301.04041). -->
<!-- Some of my past research includes applications of [conformal prediction in contextual bandits](https://arxiv.org/abs/2206.04405), and using [causal inference to assess digital twin models](https://arxiv.org/abs/2301.07210). -->

<!-- Before beginning my PhD, I spent 2 years as an associate developer at [Morgan Stanley](https://www.morganstanley.com/) in London. I got my Bachelor’s and Master’s degrees in Mathematics from the [University of Cambridge](https://www.cam.ac.uk/). -->

### Contact

Feel free to reach out to me at _faaiz.taufiq (at) bytedance.com_
